---
title: "Lab 08 - University of Edinburgh Art Collection"
author: "Conor Lacey"
date: "03-05-23"
output: github_document
---

### Load packages and data

```{r load-packages, message = FALSE}
suppressWarnings(library(tidyverse))
library(rvest)
library(skimr)
library(glue)
```


### Exercise 1

```{r first_url}
# set url
first_url <- "https://collections.ed.ac.uk/art/search/*:*/Collection:%22edinburgh+college+of+art%7C%7C%7CEdinburgh+College+of+Art%22?offset=0"

# read html page
page <- read_html(first_url)

titles <- page %>%
  html_nodes(".iteminfo") %>%
  html_node("h3 a") %>%
  html_text() %>% 
  str_squish()

links <- page %>%
  html_nodes(".iteminfo") %>%   # same nodes
  html_node("h3 a") %>%         # as before
  html_attr("href") %>%         # but get href attribute instead of text
  str_replace(pattern =".", replacement = "https://collections.ed.ac.uk") #replacing
```

### Exercise 2

```{r Names}
names <- page %>% 
  html_nodes(".iteminfo") %>% 
  html_node(".artist") %>% 
  html_attr("title")
```

### Exercise 3

```{r uoe_art}
uoe_art <- tibble(title = titles, 
                  name = names,
                  link = links)
uoe_art
```

```{r load-data, message = FALSE, eval = FALSE}
# Remove eval = FALSE or set it to TRUE once data is ready to be loaded
uoe_art <- read_csv("data/uoe-art.csv")
```

### Exercise 4

```{r second_url}
# set url
second_url <- "https://collections.ed.ac.uk/art/search/*:*/Collection:%22edinburgh+college+of+art%7C%7C%7CEdinburgh+College+of+Art%22?offset=10"

# read html page
page <- read_html(second_url)

titles <- page %>%
  html_nodes(".iteminfo") %>%
  html_node("h3 a") %>%
  html_text() %>% 
  str_squish()

links <- page %>%
  html_nodes(".iteminfo") %>%   # same nodes
  html_node("h3 a") %>%         # as before
  html_attr("href") %>%         # but get href attribute instead of text
  str_replace(pattern =".", replacement = "https://collections.ed.ac.uk") #replacing

names <- page %>% 
  html_nodes(".iteminfo") %>% 
  html_node(".artist") %>% 
  html_attr("title")

second_ten <- tibble(title = titles, 
                  name = names,
                  link = links)
second_ten
```

### Exercises 5

```{r}
scrape_page <- function(url){
  
  # read page
  page <- read_html(url)
  
  # scrape titles
  titles <- page %>%
    html_nodes(".iteminfo") %>%
    html_node("h3 a") %>%
    html_text() %>% 
    str_squish()
  
  # scrape links
  links <- page %>%
    html_nodes(".iteminfo") %>%   # same nodes
    html_node("h3 a") %>%         # as before
    html_attr("href") %>%         # but get href attribute instead of text
    str_replace(pattern =".", replacement = "https://collections.ed.ac.uk") #replacing
  
  # scrape artists 
  names <- page %>% 
    html_nodes(".iteminfo") %>% 
    html_node(".artist") %>% 
    html_attr("title")
  
  # create and return tibble
  tibble(title = titles, 
         name = names,
         link = links)
  
}
```

### Exercise 6

``` {r test-function}
scrape_page(first_url)
scrape_page(second_url)
```


### Exercise 7

```{r URLs}
# list of urls to be scraped ---------------------------------------------------

root <- "https://collections.ed.ac.uk/art/search/*:*/Collection:%22edinburgh+college+of+art%7C%7C%7CEdinburgh+College+of+Art%22?offset="
numbers <- seq(from = 0, to = 3010, by = 10)
urls <- glue("{root}{numbers}")

# map over all urls and output a data frame ------------------------------------
```

Exercise 8

```{r uoe_art-dataframe}
uoe_art <- map_dfr(urls, scrape_page)
```

### Exercise 9

```{r write-dataframe}
# write out data frame ---------------------------------------------------------
write_csv(uoe_art, file = "data/uoe-art.csv")
```
